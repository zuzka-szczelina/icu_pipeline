{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e9f43980-e1a5-4f0f-a62f-148ddedb8b9d",
   "metadata": {
    "id": "e9f43980-e1a5-4f0f-a62f-148ddedb8b9d"
   },
   "source": [
    "# RNN\n",
    "\n",
    "I used an example from the series \\'Machine Learning with PyTorch and Scikit-Learn\\' by Sebastian Raschka (Chapter 15, Project two - character-level language modeling in PyTorch) to create a RNN model and train it.\n",
    "\n",
    "To accelerate the model training I used Google Colab environment where I specified Runtime type as *Python 3* and Hardware accelerator as *T4 GPU*. For this purpose I used *.to(device)* method to perform relevant tensors device conversion to GPU.\n",
    "\n",
    "This noteseries is adapted to be run in Google Colab environment.\\\n",
    "Section **6.** (Training the model) is included to show how I trained the model. You can decide whether you want to perform the training yourself or load the results of the training I did by choosing between **perform_model_training** and **load_pretrained_model** modes below:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d7MbHejEnSmc",
   "metadata": {
    "id": "d7MbHejEnSmc"
   },
   "outputs": [],
   "source": [
    "# training_mode = 'perform_model_training'\n",
    "training_mode = 'load_pretrained_model'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bdp2btynuSH",
   "metadata": {
    "id": "7bdp2btynuSH"
   },
   "source": [
    "## 1. Required imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b12e135-e52f-4529-9ea2-1faba71a5c81",
   "metadata": {
    "id": "1b12e135-e52f-4529-9ea2-1faba71a5c81"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.distributions.categorical import Categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2U3P_MzyS4Nx",
   "metadata": {
    "id": "2U3P_MzyS4Nx"
   },
   "source": [
    "Here I'm checking Google Colab module installation and whether hardware accelerator was set correctly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "Ea4Lelz8Saav",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ea4Lelz8Saav",
    "outputId": "95c5f0e6-c326-4031-9d26-507ca623cd11"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch version:  2.5.0+cpu\n",
      "GPU Available: False\n",
      "device:  cpu\n"
     ]
    }
   ],
   "source": [
    "print('torch version: ',torch.__version__)\n",
    "\n",
    "print(\"GPU Available:\", torch.cuda.is_available())\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "  device = torch.device(\"cuda:0\")\n",
    "else:\n",
    "  device = \"cpu\"\n",
    "print('device: ', device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "194c91cb-c303-421e-83fc-a335b0e7901f",
   "metadata": {
    "id": "2b67ae47-b1b7-4ddf-ac13-97d37bb74495"
   },
   "source": [
    "## 2. Data preparation\n",
    "Time series to be uploaded here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e2f29263-21b1-444a-8857-48500694fc32",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wi3MZ1UfHOw8",
    "outputId": "01935789-6ab8-43a8-963a-d008319dc215"
   },
   "outputs": [],
   "source": [
    "param = 'saturacja_prc'\n",
    "df = pd.read_csv('data/df_augmented_' + param + '.csv', parse_dates=['date'], date_format='%Y-%m-%d %H:%M:%S')\n",
    "df.set_index('date', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "36e678b3-f925-4b28-afa8-3e9964b8d57b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([100, 100,  99, ...,  96,  94,  95])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.values.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0c95512c-81ad-41e7-95bb-3ed2dc187f8e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wi3MZ1UfHOw8",
    "outputId": "01935789-6ab8-43a8-963a-d008319dc215"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[np.int64(83),\n",
       " np.int64(84),\n",
       " np.int64(85),\n",
       " np.int64(86),\n",
       " np.int64(87),\n",
       " np.int64(88),\n",
       " np.int64(89),\n",
       " np.int64(90),\n",
       " np.int64(91),\n",
       " np.int64(92),\n",
       " np.int64(93),\n",
       " np.int64(94),\n",
       " np.int64(95),\n",
       " np.int64(96),\n",
       " np.int64(97),\n",
       " np.int64(98),\n",
       " np.int64(99),\n",
       " np.int64(100),\n",
       " np.int64(101),\n",
       " np.int64(102),\n",
       " np.int64(103),\n",
       " np.int64(104),\n",
       " np.int64(105)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_values = df.values.flatten()\n",
    "values_set = sorted(set(pd.unique(all_values)))\n",
    "values_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "71ec8baf-7915-4cbb-b861-613a0dd9c754",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "71ec8baf-7915-4cbb-b861-613a0dd9c754",
    "outputId": "510f0f13-f81c-4784-a7a8-ff77a2c28bd3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All series include:\n",
      "total values: 3590000\n",
      "unique values: 23\n"
     ]
    }
   ],
   "source": [
    "print('All series include:')\n",
    "print(f'total values: {len(all_values)}\\nunique values: {len(values_set)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6575fcb6-45c7-48bf-a124-ee3e24ab21f8",
   "metadata": {},
   "source": [
    "I'm gonna use first 3000(???) series for training (and validation) and ....(???) for testing - idk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15d916f1-26ec-49dd-813e-1ee3cda0ab3c",
   "metadata": {},
   "source": [
    "Below a *values_array* is created containing all the unique values present in the series and a dictionary *encoding_dict* assigning an unique integer to each character. *encoding_dict* is used to generate a *values* version - *df_encoded* - where all values are replaced with their numerical representations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0f0f5bd7-2d63-464f-af1d-897196d9c331",
   "metadata": {
    "id": "0f0f5bd7-2d63-464f-af1d-897196d9c331"
   },
   "outputs": [],
   "source": [
    "encoding_dict = {val: i for i, val in enumerate(values_set)}\n",
    "values_array = np.array(values_set)\n",
    "df_encoded = df.map(lambda val: encoding_dict[val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "DiH6qROzG7tz",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DiH6qROzG7tz",
    "outputId": "a06f436f-503d-4f8c-fd57-b99fb0926cea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unique values array:\n",
      " [ 83  84  85  86  87  88  89  90  91  92  93  94  95  96  97  98  99 100\n",
      " 101 102 103 104 105]\n"
     ]
    }
   ],
   "source": [
    "print('unique values array:\\n', values_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f73f0b34-21b9-4e2d-abcd-633acfdfda0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{np.int64(83): 0,\n",
       " np.int64(84): 1,\n",
       " np.int64(85): 2,\n",
       " np.int64(86): 3,\n",
       " np.int64(87): 4,\n",
       " np.int64(88): 5,\n",
       " np.int64(89): 6,\n",
       " np.int64(90): 7,\n",
       " np.int64(91): 8,\n",
       " np.int64(92): 9,\n",
       " np.int64(93): 10,\n",
       " np.int64(94): 11,\n",
       " np.int64(95): 12,\n",
       " np.int64(96): 13,\n",
       " np.int64(97): 14,\n",
       " np.int64(98): 15,\n",
       " np.int64(99): 16,\n",
       " np.int64(100): 17,\n",
       " np.int64(101): 18,\n",
       " np.int64(102): 19,\n",
       " np.int64(103): 20,\n",
       " np.int64(104): 21,\n",
       " np.int64(105): 22}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoding_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "71d2f974-2495-4a62-b102-7cc51e1f489b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aug_series_00001</th>\n",
       "      <th>aug_series_00002</th>\n",
       "      <th>aug_series_00003</th>\n",
       "      <th>aug_series_00004</th>\n",
       "      <th>aug_series_00005</th>\n",
       "      <th>aug_series_00006</th>\n",
       "      <th>aug_series_00007</th>\n",
       "      <th>aug_series_00008</th>\n",
       "      <th>aug_series_00009</th>\n",
       "      <th>aug_series_00010</th>\n",
       "      <th>...</th>\n",
       "      <th>aug_series_09991</th>\n",
       "      <th>aug_series_09992</th>\n",
       "      <th>aug_series_09993</th>\n",
       "      <th>aug_series_09994</th>\n",
       "      <th>aug_series_09995</th>\n",
       "      <th>aug_series_09996</th>\n",
       "      <th>aug_series_09997</th>\n",
       "      <th>aug_series_09998</th>\n",
       "      <th>aug_series_09999</th>\n",
       "      <th>aug_series_10000</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2023-11-13 14:00:00</th>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>16</td>\n",
       "      <td>19</td>\n",
       "      <td>17</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>16</td>\n",
       "      <td>18</td>\n",
       "      <td>14</td>\n",
       "      <td>...</td>\n",
       "      <td>18</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>18</td>\n",
       "      <td>17</td>\n",
       "      <td>16</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-11-13 15:00:00</th>\n",
       "      <td>18</td>\n",
       "      <td>16</td>\n",
       "      <td>17</td>\n",
       "      <td>18</td>\n",
       "      <td>19</td>\n",
       "      <td>15</td>\n",
       "      <td>17</td>\n",
       "      <td>16</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>...</td>\n",
       "      <td>16</td>\n",
       "      <td>17</td>\n",
       "      <td>18</td>\n",
       "      <td>17</td>\n",
       "      <td>16</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>16</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-11-13 16:00:00</th>\n",
       "      <td>15</td>\n",
       "      <td>16</td>\n",
       "      <td>15</td>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "      <td>17</td>\n",
       "      <td>15</td>\n",
       "      <td>14</td>\n",
       "      <td>17</td>\n",
       "      <td>16</td>\n",
       "      <td>...</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 10000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     aug_series_00001  aug_series_00002  aug_series_00003  \\\n",
       "date                                                                        \n",
       "2023-11-13 14:00:00                17                17                16   \n",
       "2023-11-13 15:00:00                18                16                17   \n",
       "2023-11-13 16:00:00                15                16                15   \n",
       "\n",
       "                     aug_series_00004  aug_series_00005  aug_series_00006  \\\n",
       "date                                                                        \n",
       "2023-11-13 14:00:00                19                17                15   \n",
       "2023-11-13 15:00:00                18                19                15   \n",
       "2023-11-13 16:00:00                14                15                17   \n",
       "\n",
       "                     aug_series_00007  aug_series_00008  aug_series_00009  \\\n",
       "date                                                                        \n",
       "2023-11-13 14:00:00                15                16                18   \n",
       "2023-11-13 15:00:00                17                16                18   \n",
       "2023-11-13 16:00:00                15                14                17   \n",
       "\n",
       "                     aug_series_00010  ...  aug_series_09991  \\\n",
       "date                                   ...                     \n",
       "2023-11-13 14:00:00                14  ...                18   \n",
       "2023-11-13 15:00:00                18  ...                16   \n",
       "2023-11-13 16:00:00                16  ...                15   \n",
       "\n",
       "                     aug_series_09992  aug_series_09993  aug_series_09994  \\\n",
       "date                                                                        \n",
       "2023-11-13 14:00:00                17                17                17   \n",
       "2023-11-13 15:00:00                17                18                17   \n",
       "2023-11-13 16:00:00                15                13                14   \n",
       "\n",
       "                     aug_series_09995  aug_series_09996  aug_series_09997  \\\n",
       "date                                                                        \n",
       "2023-11-13 14:00:00                16                16                18   \n",
       "2023-11-13 15:00:00                16                18                18   \n",
       "2023-11-13 16:00:00                15                15                15   \n",
       "\n",
       "                     aug_series_09998  aug_series_09999  aug_series_10000  \n",
       "date                                                                       \n",
       "2023-11-13 14:00:00                17                16                14  \n",
       "2023-11-13 15:00:00                18                16                17  \n",
       "2023-11-13 16:00:00                14                15                15  \n",
       "\n",
       "[3 rows x 10000 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_encoded.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df5ab9e8-d555-4564-9b13-e1acb82f1d0f",
   "metadata": {
    "id": "df5ab9e8-d555-4564-9b13-e1acb82f1d0f"
   },
   "source": [
    "## 3. ML Dataset construction\n",
    "Encoded values is divided into chunks to be fed into the model:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3a778319-d821-44c4-bd59-73ce26cb928b",
   "metadata": {
    "id": "3a778319-d821-44c4-bd59-73ce26cb928b"
   },
   "outputs": [],
   "source": [
    "seq_length = 40\n",
    "chunk_size = seq_length + 1\n",
    "series_chunks_list = []\n",
    "for i, col in enumerate(df_encoded.columns):\n",
    "    series_chunks_list.append([df_encoded[col].values[i: i + chunk_size] for i in range(len(df_encoded[col]) - chunk_size)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "698fb6a8-eed6-4a71-856f-0f19f114473b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(series_chunks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0819be91-e619-48ba-95e0-8f0db6b1aab1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "318"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(series_chunks_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bef3374f-11b4-4e86-a2d1-9b334ab70aee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(series_chunks_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7216a460-8c25-46a4-a13a-20ba0b05d5e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "series_chunks_tensor = torch.tensor(np.array(series_chunks_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "dcd110da-dabe-42bc-970e-712b558deb0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8000, 41])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series_chunks_tensor[0:8000].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6b415dda-2155-43d3-b15e-279f64c63277",
   "metadata": {},
   "outputs": [],
   "source": [
    "series_chunks_training = torch.flatten(series_chunks_tensor[0:3000], start_dim=0, end_dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d5ddadb-f5bf-4d27-8a4e-5fd0fe0d54cb",
   "metadata": {},
   "source": [
    "valuesDataset class is created. It's instance, *seq_dataset*, stores the sequences samples and their corresponding targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "dc6376e8-a7cb-4613-815c-128c7192fdff",
   "metadata": {
    "id": "dc6376e8-a7cb-4613-815c-128c7192fdff"
   },
   "outputs": [],
   "source": [
    "class valuesDataset(Dataset):\n",
    "    def __init__(self, chunks_tensor):\n",
    "        self.chunks_tensor = chunks_tensor\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.chunks_tensor)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        chunk = self.chunks_tensor[idx]\n",
    "        return chunk[:-1].long(), chunk[1:].long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d72533db-82e8-4212-91c0-a190339b9cca",
   "metadata": {
    "id": "d72533db-82e8-4212-91c0-a190339b9cca"
   },
   "outputs": [],
   "source": [
    "seq_dataset = valuesDataset(series_chunks_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "bd585cfd-dcfe-4950-8272-66f7139bf83e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bd585cfd-dcfe-4950-8272-66f7139bf83e",
    "outputId": "c2cc56ab-d215-4a26-c360-ce3e6fca23b6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model input (x):  array([100, 101,  98,  97,  98,  96,  95,  97,  96,  97,  96,  95,  96,\n",
      "        95,  95,  96,  95,  96,  96,  97,  94,  91,  91,  89,  92,  93,\n",
      "        91,  92,  95,  94,  95,  93,  94,  95,  93,  95,  95,  94,  94,\n",
      "        98])\n",
      "Model target (y): array([101,  98,  97,  98,  96,  95,  97,  96,  97,  96,  95,  96,  95,\n",
      "        95,  96,  95,  96,  96,  97,  94,  91,  91,  89,  92,  93,  91,\n",
      "        92,  95,  94,  95,  93,  94,  95,  93,  95,  95,  94,  94,  98,\n",
      "        95])\n",
      "Model input (x):  array([101,  98,  97,  98,  96,  95,  97,  96,  97,  96,  95,  96,  95,\n",
      "        95,  96,  95,  96,  96,  97,  94,  91,  91,  89,  92,  93,  91,\n",
      "        92,  95,  94,  95,  93,  94,  95,  93,  95,  95,  94,  94,  98,\n",
      "        95])\n",
      "Model target (y): array([98, 97, 98, 96, 95, 97, 96, 97, 96, 95, 96, 95, 95, 96, 95, 96, 96,\n",
      "       97, 94, 91, 91, 89, 92, 93, 91, 92, 95, 94, 95, 93, 94, 95, 93, 95,\n",
      "       95, 94, 94, 98, 95, 94])\n",
      "Model input (x):  array([98, 97, 98, 96, 95, 97, 96, 97, 96, 95, 96, 95, 95, 96, 95, 96, 96,\n",
      "       97, 94, 91, 91, 89, 92, 93, 91, 92, 95, 94, 95, 93, 94, 95, 93, 95,\n",
      "       95, 94, 94, 98, 95, 94])\n",
      "Model target (y): array([97, 98, 96, 95, 97, 96, 97, 96, 95, 96, 95, 95, 96, 95, 96, 96, 97,\n",
      "       94, 91, 91, 89, 92, 93, 91, 92, 95, 94, 95, 93, 94, 95, 93, 95, 95,\n",
      "       94, 94, 98, 95, 94, 96])\n",
      "Model input (x):  array([97, 98, 96, 95, 97, 96, 97, 96, 95, 96, 95, 95, 96, 95, 96, 96, 97,\n",
      "       94, 91, 91, 89, 92, 93, 91, 92, 95, 94, 95, 93, 94, 95, 93, 95, 95,\n",
      "       94, 94, 98, 95, 94, 96])\n",
      "Model target (y): array([98, 96, 95, 97, 96, 97, 96, 95, 96, 95, 95, 96, 95, 96, 96, 97, 94,\n",
      "       91, 91, 89, 92, 93, 91, 92, 95, 94, 95, 93, 94, 95, 93, 95, 95, 94,\n",
      "       94, 98, 95, 94, 96, 97])\n"
     ]
    }
   ],
   "source": [
    "for i, (seq, target) in enumerate(seq_dataset):\n",
    "    print('Model input (x): ', repr(values_array[seq]))\n",
    "    print('Model target (y):', repr(values_array[target]))\n",
    "    if i==3:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45ff935b-8261-4517-8f78-2cbba6b5341e",
   "metadata": {
    "id": "45ff935b-8261-4517-8f78-2cbba6b5341e"
   },
   "source": [
    "Next, a dataloader is created - which is an object used to pass data into the model in the form of \\'batches\\' (groups of specified size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "66fee067-247f-4eae-bb65-711a3842bf68",
   "metadata": {
    "id": "66fee067-247f-4eae-bb65-711a3842bf68"
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(1)\n",
    "batch_size = 64\n",
    "seq_dataloader = DataLoader(seq_dataset, batch_size=batch_size, shuffle=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "590935f5-6a92-4ebc-8022-58ac3d1ff9ae",
   "metadata": {
    "id": "590935f5-6a92-4ebc-8022-58ac3d1ff9ae"
   },
   "source": [
    "## 4. Defining a RNN model\n",
    "\n",
    "*RNN* class defines RNN model's architecture:\n",
    "\n",
    "#### __init__ method:\n",
    "\n",
    "**self.embedding** is a table that stores an embedding vector for each unique character (we generate one embedding vector for each character by specifying vocab_size=len(values_array) below). Each embedding vector has length of embed_dim\n",
    "\n",
    "**self.rnn** is a neural network we will use. We specify its properties using *torch.nn.LSTM* function. LSTM stands for \\'Long Short-Term Memory\\' end indicates that we will use a RNN with LSTM cells used as hidden layers. The input to a hidden layer will be a specific character represented as an embedding vector. Therefore, we specify that we expect an input to be of size of the embedding vector length (embed_dim).\\\n",
    "The output of calling self.rnn is:\\\n",
    "*output_features,\\\n",
    "(final hidden state (for each element in the sequence),\\\n",
    "final cell state (for each element in the sequence))*\\\n",
    "It is utilized in *forward* method.\n",
    "\n",
    "**self.fc** is where we define a type of transformation we will apply to the output of hidden layers\n",
    "\n",
    "**self.rnn_hidden_size** is the number of features in the hidden state of RNN\n",
    "\n",
    "#### forward method:\n",
    "Define the computation performed at every model call (we can use this method because our RNN class inherits form class Module, which is a PyTorch Base class for all neural network modules)\n",
    "\n",
    "#### init_hidden method:\n",
    "Is where we initialize the state of a hidden layer and LSTM cell. (which will be used in forward method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3db9ef83-3367-4b4f-a16a-1aa8be171556",
   "metadata": {
    "id": "3db9ef83-3367-4b4f-a16a-1aa8be171556"
   },
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, rnn_hidden_size):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
    "        self.rnn = nn.LSTM(input_size=embed_dim,\n",
    "                           hidden_size=rnn_hidden_size,\n",
    "                           batch_first=True)\n",
    "        self.fc = nn.Linear(in_features=rnn_hidden_size,\n",
    "                            out_features=vocab_size)\n",
    "\n",
    "        self.rnn_hidden_size = rnn_hidden_size\n",
    "\n",
    "    def forward(self, x, hidden, cell):\n",
    "        out = self.embedding(x).unsqueeze(1)\n",
    "        out, (hidden, cell) = self.rnn(out, (hidden, cell))\n",
    "        out = self.fc(out).reshape(out.size(0), -1)\n",
    "        return out, hidden, cell\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        hidden = torch.zeros(1, batch_size, self.rnn_hidden_size).to(device)\n",
    "        cell = torch.zeros(1, batch_size, self.rnn_hidden_size).to(device)\n",
    "        return hidden, cell"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dade0438-2cd6-4816-9912-c66958812ed0",
   "metadata": {
    "id": "dade0438-2cd6-4816-9912-c66958812ed0"
   },
   "source": [
    "## 5. Creating an instance of the defined model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6b111a04-4fe8-41fe-8b6f-1a826c908016",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6b111a04-4fe8-41fe-8b6f-1a826c908016",
    "outputId": "c9227f83-d834-4418-dc23-e3bbe7a6970f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNN(\n",
       "  (embedding): Embedding(23, 256)\n",
       "  (rnn): LSTM(256, 512, batch_first=True)\n",
       "  (fc): Linear(in_features=512, out_features=23, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = len(values_array)\n",
    "embed_dim = 256\n",
    "rnn_hidden_size = 512\n",
    "model = RNN(vocab_size, embed_dim, rnn_hidden_size).to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9298a0ef-0e29-4507-b71e-32befe1d6888",
   "metadata": {
    "id": "9298a0ef-0e29-4507-b71e-32befe1d6888"
   },
   "source": [
    "define loss function and optimizer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "55a83abf-d50a-49d2-9a76-286c06b34c8d",
   "metadata": {
    "id": "55a83abf-d50a-49d2-9a76-286c06b34c8d"
   },
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "374a6773-6145-4bc7-878b-81bf51972b49",
   "metadata": {
    "id": "374a6773-6145-4bc7-878b-81bf51972b49"
   },
   "source": [
    "## 6. Training the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2bd47fb-7da7-4d61-acb7-9de96b70ee55",
   "metadata": {
    "id": "f2bd47fb-7da7-4d61-acb7-9de96b70ee55"
   },
   "source": [
    "Model is trained for multiple epochs. In each epoch only one batch is used.\\\n",
    "For each epoch we perform the following:\n",
    "1. hidden layer and cell states initialization\n",
    "2. use seq_dataloader as iterator object and load one batch (set of 64 input sequences and corresponding target sequences)\n",
    "3. reset the gradients of all optimized tensors.\n",
    "4. initialize loss (between predicted sequences and target sequences of loaded batch) as 0\n",
    "5. we use for loop to:\\\n",
    "   I. predict next character for each character in the input_sequence. It is done simultaneously for all input sequences in the batch.\\\n",
    "   II.Compute temporary loss as sum of losses for all values\n",
    "6. Compute loss gradients after iterating through all values.\n",
    "7. Perform optimization step to update model parameters (function .step() can be called once the gradients are computed using .backward())\n",
    "8. Compute final loss for a batch (dividing by the number of values each sequence had)\n",
    "9. Printing current loss updates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7942dfc-5a3f-4c32-a449-c683e59f249c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d7942dfc-5a3f-4c32-a449-c683e59f249c",
    "outputId": "17745a5e-8aca-4cc2-fda9-d00242a23578"
   },
   "outputs": [],
   "source": [
    "if training_mode == 'perform_model_training':\n",
    "\n",
    "    num_epochs = 10000\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        hidden, cell = model.init_hidden(batch_size)\n",
    "        seq_batch, target_batch = next(iter(seq_dataloader))\n",
    "        seq_batch = seq_batch.to(device)\n",
    "        target_batch = target_batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        loss = 0\n",
    "        for c in range(seq_length):\n",
    "            pred, hidden, cell = model(seq_batch[:, c], hidden, cell)\n",
    "            loss += loss_fn(pred, target_batch[:, c])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss = loss.item()/seq_length\n",
    "        if epoch % 500 == 0:\n",
    "            print(f'Epoch {epoch} loss: {loss:.4f}')\n",
    "    print('time passed: ', time.time() - start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9RJvCrlMd-f0",
   "metadata": {
    "id": "9RJvCrlMd-f0"
   },
   "source": [
    "## 7. Model saving and loading\n",
    "\n",
    "### I. saving and loading after training:\n",
    "\n",
    "There are 2 ways to save model training results:\\\n",
    "**method 1.** : saving the whole model object (i.e. model object of a specified architecture and its learned parameters)\\\n",
    "**method 2.** : saving just parameters (to reuse the parameters one needs to create a model object of the same architecture as the trained one and load them into the model)\n",
    "\n",
    "I'm using the **method 1.**, however, below I include commented code for **method 2.**.\n",
    "\n",
    "model.eval() function is called to indicate that the model will now be used in evaluation mode (i.e. for inference). It's because some layers behave differently during training and inference and need their mode to be set in advance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "RTG9MrqNleXJ",
   "metadata": {
    "id": "RTG9MrqNleXJ"
   },
   "outputs": [],
   "source": [
    "saving_method = 'method_1'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "oqyrXOF4lnKr",
   "metadata": {
    "id": "oqyrXOF4lnKr"
   },
   "source": [
    "**method 1.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "-hXJv7uAcfQt",
   "metadata": {
    "id": "-hXJv7uAcfQt"
   },
   "outputs": [],
   "source": [
    "if training_mode == 'perform_model_training' and saving_method == 'method_1':\n",
    "    torch.save(model, 'data/models/self_trained_model.pt')\n",
    "\n",
    "    trained_model = torch.load('data/models/self_trained_model.pt', weights_only=False, map_location=device)\n",
    "    trained_model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vYzdBvJFlL90",
   "metadata": {
    "id": "vYzdBvJFlL90"
   },
   "source": [
    "**method 2.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rKH3oxOQdJGv",
   "metadata": {
    "id": "rKH3oxOQdJGv"
   },
   "outputs": [],
   "source": [
    "# if training_mode == 'perform_model_training' and saving_method == 'method_2':\n",
    "#     torch.save(trained_model.state_dict(), 'data/models/self_trained_model_state_dict.pt')\n",
    "\n",
    "#     trained_model = RNN(vocab_size, embed_dim, rnn_hidden_size)\n",
    "#     trained_model.load_state_dict(torch.load('data/models/self_trained_model_state_dict.pt', weights_only=False))\n",
    "#     trained_model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cc7db75-e532-41d1-a4e6-9f126b0c3ce8",
   "metadata": {},
   "source": [
    "### II. loading a pretrained model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "QLkZkXF9lGBQ",
   "metadata": {
    "id": "QLkZkXF9lGBQ"
   },
   "outputs": [],
   "source": [
    "if training_mode == 'load_pretrained_model':\n",
    "    trained_model = torch.load('data/models/einstein_pretrained_model.pt', map_location=device, weights_only=False)\n",
    "    trained_model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "WprMXBslykDt",
   "metadata": {
    "id": "WprMXBslykDt"
   },
   "source": [
    "## 8. values generating function\n",
    "\n",
    "Below function is defined that utilizes the model to generate values on the basis of the series.\n",
    "\n",
    "The rate to with a generated values may be meaningful can be altered by changing a **predictability_factor** - the bigger the more predictable (and likely more meaningful) the generated values will be.\n",
    "\n",
    "values are added to starting string one at a time. Randomness is enabled by usage of Categorical() class and sample() function - the added value is not always the one with the highest probability. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f47ff58d-4652-43ec-956b-58ea45da5297",
   "metadata": {
    "id": "f47ff58d-4652-43ec-956b-58ea45da5297"
   },
   "outputs": [],
   "source": [
    "def generate_values(model, starting_str, len_generated_values=500, predictability_factor=2.0):\n",
    "    encoded_input = torch.tensor(\n",
    "        [encoding_dict[s] for s in starting_str]\n",
    "    )\n",
    "    encoded_input = torch.reshape(encoded_input, (1, -1)).to(device)\n",
    "    generated_str = starting_str\n",
    "\n",
    "    model.eval()\n",
    "    hidden, cell = model.init_hidden(1)\n",
    "    for c in range(len(starting_str)-1):\n",
    "        _, hidden, cell = model(\n",
    "            encoded_input[:, c].view(1), hidden, cell\n",
    "        )\n",
    "\n",
    "    last_char = encoded_input[:, -1]\n",
    "    for i in range(len_generated_values):\n",
    "        logits, hidden, cell = model(\n",
    "            last_char.view(1), hidden, cell\n",
    "        )\n",
    "        logits = torch.squeeze(logits, 0)\n",
    "        scaled_logits = logits * predictability_factor\n",
    "        m = Categorical(logits=scaled_logits)\n",
    "        last_char = m.sample()\n",
    "        generated_str += str(values_array[last_char])\n",
    "\n",
    "    return generated_str"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "PwfmRIlBGyHv",
   "metadata": {
    "id": "PwfmRIlBGyHv"
   },
   "source": [
    "## 9. Final use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "_IQu9w3OGwnw",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_IQu9w3OGwnw",
    "outputId": "36fef066-703c-469c-851e-be14ab2addbd"
   },
   "outputs": [],
   "source": [
    "print(generate_values(trained_model, starting_str='Time and Space'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b9624c-b4e5-4f21-9307-bc997e705747",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_IQu9w3OGwnw",
    "outputId": "36fef066-703c-469c-851e-be14ab2addbd"
   },
   "outputs": [],
   "source": [
    "print(generate_values(trained_model, starting_str='Time and Space'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "389fb0b7-1c23-4f2e-9753-78b38957a94c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_IQu9w3OGwnw",
    "outputId": "36fef066-703c-469c-851e-be14ab2addbd"
   },
   "outputs": [],
   "source": [
    "print(generate_values(trained_model, starting_str='Time and Space'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e454cf-9e36-4693-bc6b-3c71a54813bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#embedding problematyczny\n",
    "#model od promo używa tylko tego szeregu\n",
    "\n",
    "#to nie:\n",
    "\n",
    "#usunąć anomalie z szeregu\n",
    "#augumentacja tego z usuniętymi anomaliami\n",
    "#forcasting bez anomalii i badamy jakość forecastingu na podstawie rozkładu residuów\n",
    "#jeśli będzie ok to dodajemy anomalie (losowe anomalie do róznych szeregów)\n",
    "\n",
    "#detektor trendu -ale to raczje nie zdążymy\n",
    "#--------------------------------------------------\n",
    "#To tak:\n",
    "#jeden parametr\n",
    "#dla orginalnego i jednego augumentowanego (2 szeregi) szeregu spróbować model od promo 1 i 2\n",
    "#porównać rozkład resuguów dla obu w funkcji seq_length [5, 10, 15, 20] w formie wykresów (jeden dla każdej długości seq_lengt 2 modele na tym plocie)\n",
    "#plus w tekście można std odchylenie i średnią\n",
    "#pierwsze 100 zakładamy że to uczenie, dla kolejnych dalszych sprawdzamy forecasting"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
